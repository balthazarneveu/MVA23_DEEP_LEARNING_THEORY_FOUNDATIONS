{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgkYZB8ay6UQ"
   },
   "source": [
    "# **TP 3: Uncertainty Applications**\n",
    "\n",
    "This last lab session will focus on applications based on uncertainty estimation. We will first use MC Dropout variational inference to qualitatively evaluate the most uncertain images for classification . \n",
    "Then, we'll apply the uncertainty for an important application: failure prediction.\n",
    "\n",
    "**Goal**: Take hand on applying uncertainty estimation for classification and use it for failure prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HPtHehyy6UV"
   },
   "source": [
    "## **Preliminary: download MNIST dataset**\n",
    "\n",
    "**First, we will download the MNIST dataset** (train/test images and labels): [https://thome.isir.upmc.fr/classes/MVA/mnist-data.pcl](https://thome.isir.upmc.fr/classes/MVA/mnist-data.pcl)\n",
    "\n",
    "**Then, the dataset will be loaded into memory to speed up computations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://thome.isir.upmc.fr/classes/MVA/mnist-data.pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OXV3DJMcy6UW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from matplotlib.pyplot import imread\n",
    "%matplotlib inline\n",
    "import _pickle as pickle \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "outfile = 'mnist-data.pcl'\n",
    "[X_train, y_train,X_test, y_test] = pickle.load( open( outfile, \"rb\" ) )\n",
    " \n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaSmWGuMy6UY"
   },
   "source": [
    "## **Part I : MC Dropout for classification on MNIST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y6vXv4by6UY"
   },
   "source": [
    "**We will design a 'LeNet-like' Convolutional neural network (ConvNet) with the following architecture:**\n",
    "\n",
    "- A conv layer with 16 5x5 filters, followed by a max pooling a size (2,2)\n",
    "- A conv layer with 32 5x5 filters, followed by a max pooling a size (2,2). \n",
    "- From this stage, flatten the tensor\n",
    "- A dropout layer with p=0.5\n",
    "- A fully connected layer with 100 hidden units, and ReLU activation\n",
    "- A dropout layer with p=0.25\n",
    "- A fully connected layer with 10 output classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yHUfPmfy6UZ"
   },
   "source": [
    "### **I.1: Training a ConvNet with dropout on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ei4N3knyy6Ua"
   },
   "outputs": [],
   "source": [
    "#TO DO: Code a LeNet-style neural network. \n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, c_in=1, h1=16, h2=32, h_classifier=100, n_classes=10, H=28, W=28, p1=0.5, p2=0.25):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, h1, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.c2 = nn.Conv2d(h1, h2, 5)\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            self.c1, self.relu, self.mp, \n",
    "            self.c2, self.relu, self.mp,\n",
    "        )\n",
    "        conv_output_size = ((H-4)//2 - 4 )//2 *  ((W-4)//2 - 4 )//2\n",
    "        self.flattened_dim = conv_output_size*h2\n",
    "        self.dropout1 = nn.Dropout(p=p1)\n",
    "        self.dropout2 = nn.Dropout(p=p2)\n",
    "        self.fc1 = nn.Linear(self.flattened_dim, h_classifier)\n",
    "        self.fc2 = nn.Linear(h_classifier, n_classes)\n",
    "        \n",
    "\n",
    "        self.classification_layers = nn.Sequential(\n",
    "            self.dropout1,\n",
    "            self.fc1,\n",
    "            self.relu,\n",
    "            self.fc2\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        features = self.conv_layers(x) # N, C=32, 4, 4  ((H-4//2) - 4 )//2\n",
    "        # print(features.shape)\n",
    "        flattened_feats = features.view(-1, self.flattened_dim)\n",
    "        logits = self.classification_layers(flattened_feats)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test(X_train: torch.Tensor):\n",
    "    \"\"\"Check that the sizes are correct\n",
    "    \"\"\"\n",
    "    n_classes = 7 # Fake number of classes, just to make sure\n",
    "    _, C, H, W = X_train.shape\n",
    "    net = LeNet(c_in=C, H=H, W=W, n_classes=7)\n",
    "    if(use_cuda ==True):\n",
    "        net.cuda() \n",
    "    else:\n",
    "        net = LeNet()\n",
    "    batch_size = 5\n",
    "    logits = net(X_train[:batch_size, ...])\n",
    "    assert logits.shape == (batch_size, n_classes)\n",
    "unit_test(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xtjr9IPty6Ua"
   },
   "source": [
    "**Now, fill the code below to train the network for 20 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Tggnb-Fry6Ub"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:31<00:00,  7.55s/it]\n"
     ]
    }
   ],
   "source": [
    "tbatch =100\n",
    "nb_epochs=20\n",
    "nbbatchs = int(X_train.shape[0]/100)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(nb_epochs)):  # loop over the dataset multiple times\n",
    "    for i in range(nbbatchs):\n",
    "        X_batch = X_train[i*100:(i+1)*100,:,:]\n",
    "        y_batch = y_train[i*100:(i+1)*100]\n",
    "        # Compute forward / backward\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = net(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# Save your model in case the session crashes\n",
    "torch.save(net.state_dict(), 'lenet_final.cpkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg-TQh1Ny6Uc"
   },
   "source": [
    "### **I.2: MC sampling on test set**\n",
    "Once your ConvNet model with dropout is trained, apply MC sampling in the test set to approximate the predictive distribution for each sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJjbZJ2Ky6Ud"
   },
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load('./simple/TP3/lenet_final.cpkt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "H2vX9b64y6Ud"
   },
   "outputs": [],
   "source": [
    "# complete the following function: parse the dataset in a batch manner, run the network with dropout \n",
    "# sampling activated to get multiple predictions for each image\n",
    "def MC_sampling(X, y , net, tbatch=100, samples=200):\n",
    "    net.eval()\n",
    "    net.training=True\n",
    "    outputs = torch.zeros(samples, X.shape[0], 10)\n",
    "    # COMPLETE WITH YOUR CODE\n",
    "    for idx in range(X.shape[0]):\n",
    "        x_in = X[i, ...].repeat(tbatch)\n",
    "        outputs[idx] = net(x_in)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7dFvgK5y6Ue",
    "outputId": "604f43c1-14a6-4c9e-fb48-328308906bbd"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m MC_samples \u001b[39m=\u001b[39m MC_sampling(X_test,y_test,net)\n",
      "\u001b[1;32m/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# COMPLETE WITH YOUR CODE\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     x_in \u001b[39m=\u001b[39m X[i, \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m]\u001b[39m.\u001b[39;49mrepeat(tbatch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     outputs[idx] \u001b[39m=\u001b[39m net(x_in)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Data/code/MVA23_DEEP_LEARNING_THEORY_FOUNDATIONS/TP3_uncertainty_applications.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "MC_samples = MC_sampling(X_test,y_test,net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OeCVnbZy6Ue"
   },
   "source": [
    "**We will now compute a classification uncertainty metric based on predictive distribution on test images.**\n",
    "\n",
    "Let us consisder an image $\\mathbf{x}$, for which we have a set of $N_S$ samples, each sample corresponding to a vector of size $N_C$ ($N_C$ being the number of classes). We compute an histogram of predictions over the $N_S$ samples: the histogram dispersion provides an indicator of the predictive uncertainty.\n",
    "Specifically, we use the following \"variation-ratio\" metric: \n",
    "\n",
    "$$ variation-ratio[\\mathbf{x}] = 1 - \\frac{f_x^{c^*}}{T}\n",
    "$$\n",
    "\n",
    "where $f_x^{c^*}$ is the number of occurences in histogram corresponding to the majority class, (*i.e.* the mode) ${c^*}$.\n",
    "\n",
    "We can compute the predictions histograms as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXJpnMf1y6Ue"
   },
   "outputs": [],
   "source": [
    "nS = MC_samples.shape[0]\n",
    "MC_samples_SM = F.softmax(MC_samples, dim=2) # Apply soft-max\n",
    "nbtest = X_test.shape[0]\n",
    "am = np.argmax(MC_samples, axis=2) # Compute predicted class for each MC sampling and each example\n",
    "hists = [np.histogram(am[:,i], range=(0,10)) for i in range(nbtest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aW4GGnPzy6Ue"
   },
   "source": [
    "Then the model predictions for each example are computing as the majority class among MC samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNnB5XJzy6Ue"
   },
   "outputs": [],
   "source": [
    "pred_vr = [0 for i in range(10000)]\n",
    "for i in range(10000):\n",
    "    pred_vr[i] = np.argmax(hists[i][0])\n",
    "pred_vr2 = torch.tensor(np.array(pred_vr)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-U8V-TCy6Ue"
   },
   "source": [
    "**From prediction histograms, compute the \"variation-ratio\" uncertainty metric:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juN8YZBdy6Uf"
   },
   "outputs": [],
   "source": [
    "fx = # COMPLETE with your code\n",
    "var_ratio = 1.0-fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98swfO_gy6Uf"
   },
   "source": [
    "We can then sort test examples by increasing confidence $f_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUm7B9BYy6Uf"
   },
   "outputs": [],
   "source": [
    "uncertain_samples = # COMPLETE with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-yMJ69Ty6Uf"
   },
   "source": [
    "**The following function can be used to draw 25 images ranked from index m regarding confidence:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjPojKvVy6Uf"
   },
   "outputs": [],
   "source": [
    "def showImages(m , var_ratio , uncertain_samples, X_test):\n",
    "    # Visualize some images\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=5, dpi=150)\n",
    "    \n",
    "    for i in range(m,m+25):\n",
    "        ist = i-m\n",
    "        title = \"VR=\"+\"{0:.3f}\".format(var_ratio[uncertain_samples[i]])\n",
    "        axes[ist // 5][ist % 5].set_title(title, fontsize=6)\n",
    "        axes[ist // 5][ist % 5].imshow(X_test[uncertain_samples[i],0,:,:].cpu(), cmap='gray')\n",
    "        axes[ist // 5][ist % 5].set_xticks([])\n",
    "        axes[ist // 5][ist % 5].set_yticks([])\n",
    "    fig.set_size_inches(5, 5)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpOQ5SZ7y6Ug"
   },
   "source": [
    "**Explore image with low and high confidence. Look at images and comment the confidence metric.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pMmXgbKy6Ug"
   },
   "outputs": [],
   "source": [
    "showImages(0,var_ratio , uncertain_samples, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaZR8sHdy6Ug"
   },
   "outputs": [],
   "source": [
    "showImages(8000,var_ratio , uncertain_samples, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LFuSH_hm5Pf"
   },
   "source": [
    "**Finally, the following showUncertainty function can be used to visualize the predictions for a given input image:**\n",
    "- The mean prediction over MC samples\n",
    "- The histogram predictions\n",
    "- The histogram of predictions for the 3 leading classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W88FPI3_y6Ug"
   },
   "outputs": [],
   "source": [
    "def showUncertainty(MC_sample, hist, img, title):\n",
    "    size=10\n",
    "    \n",
    "    sSM = F.softmax(MC_sample,dim=1)\n",
    "    pred_mean = sSM.mean(axis=0)\n",
    "       \n",
    "    fig = plt.figure(dpi=150)  \n",
    "    fig.suptitle(title, fontsize=\"x-large\")\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(4*5)\n",
    "    ax = plt.subplot(161)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')        \n",
    "   \n",
    "    ax = plt.subplot(162)\n",
    "    ax.bar(range(10),pred_mean)\n",
    "    ax.set_title(\"Mean Pred\")\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(size)\n",
    "    ax.set_xticks(range(10))\n",
    "    \n",
    "    ax = plt.subplot(163)\n",
    "    ax.bar(range(10),hist)\n",
    "    ax.set_title(\"Samples Pred\")\n",
    "    ax.set_xticks(range(10))\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(size)\n",
    "    \n",
    "    asorted = np.argsort(pred_mean, axis=0)\n",
    "     \n",
    "   \n",
    "    h1 = np.histogram(sSM[:,asorted[9]], range=(0.0,1.0))\n",
    "    h2 = np.histogram(sSM[:,asorted[8]], range=(0.0,1.0))\n",
    "    h3 = np.histogram(sSM[:,asorted[7]], range=(0.0,1.0))\n",
    "\n",
    "    ax =plt.subplot(164)\n",
    "    ax.bar(range(10),h1[0])\n",
    "    ax.set_title(\"Class=\"+str(asorted[9].numpy()))\n",
    "    ax.set_yticks(np.arange(0,200,20))\n",
    "    ax.set_xticks(range(10))\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(size)\n",
    "    ax = plt.subplot(165)\n",
    "    ax.bar(range(10),h2[0])\n",
    "    ax.set_title(\"Class=\"+str(asorted[8].numpy()))\n",
    "    ax.set_yticks(np.arange(0,200,20))\n",
    "    ax.set_xticks(range(10))\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(size)\n",
    "    ax = plt.subplot(166)\n",
    "    ax.bar(range(10),h3[0])\n",
    "    ax.set_title(\"Class=\"+str(asorted[7].numpy()))\n",
    "    ax.set_yticks(np.arange(0,200,20))\n",
    "    ax.set_xticks(range(10))\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(size)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyqwhY_Sy6Uh"
   },
   "outputs": [],
   "source": [
    "min =10\n",
    "max=100\n",
    "\n",
    "cpt=np.random.randint(min,max)\n",
    "index = uncertain_samples[cpt]\n",
    "    \n",
    "title = \"TRUE LABEL=\"+str(y_test[index].cpu().numpy())+\"- PRED=\"+str(pred_vr2[index].cpu().numpy())+ \" - Uncertainty=\"+str(\"{:0.2f}\".format(var_ratio[index]))+\" rank=\"+str(cpt)\n",
    "showUncertainty(MC_samples[:,index,:], hists[index][0], X_test[index,0,:,:].reshape([28,28]).cpu(), title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T84RQkmSy6Uh"
   },
   "source": [
    "## **Part II : Failure Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI_jsMW7y6Ui"
   },
   "source": [
    "**The objective is to provide confidence measures for model’s predictions that are reliable and whoseranking among samples enables to distinguish correct from incorrect predictions. Equipped with sucha confidence measure, a system could decide to stick to the prediction or, on the contrary, to handover to a human or a back-up system with, *e.g.* other sensors, or simply to trigger an alarm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thome.isir.upmc.fr/classes/MVA/failure.png\" title=\"Failure prediction\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGE_RHPzo7GH"
   },
   "source": [
    "**We will introduce ConfidNet, a specific method design to address failure prediction and we will compare it to MCDropout with entropy and Maximum Class Probability (MCP).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-p4vUTPpMyZ"
   },
   "source": [
    "### **II.1 ConfidNet**\n",
    "\n",
    "By taking the largest softmax probability as confidence estimate, MCP leads to high confidence values both for correct and erroneous predictions alike. On the other hand, when the model misclassifies an example, the probability associated to the true class $y$ is lower than the maximum one and likely to be low.\n",
    "\n",
    "Based on this observation, we can consider instead the **True Class Probability** as a suitable uncertainty criterion.\n",
    "For any admissible input $\\pmb{x}\\in \\mathcal{X}$, we assume the *true* class $y(\\pmb{x})$ is known, which we denote $y$ for simplicity. The TCP of a model $F$ is defined as  \n",
    "\\begin{equation}\n",
    "    \\text{TCP}_F(\\pmb{x},y) = P(Y=y \\vert \\pmb{x}, \\hat{\\pmb{w}})\n",
    "\\end{equation}\n",
    "\n",
    "**Theoretical guarantees.** Given a properly labelled example $(\\pmb{x},y)$, then:\n",
    "- $\\text{TCP}_F(\\pmb{x},y)> 1/2$ $\\Rightarrow$ $f(\\pmb{x}) = y$, *i.e.* the example is correctly classified by the model;%the example has been correctly classified,\n",
    "- $\\text{TCP}_F(\\pmb{x},y) < 1/K$ $\\Rightarrow$ $f(\\pmb{x}) \\neq y$, *i.e.* the example is wrongly classified by the model.\n",
    "\n",
    "However, the true classes $y$ are obviously not available when estimating confidence on test inputs. Alternatively, we can **learn TCP criterion from data** with an auxiliary model called **ConfidNet**.\n",
    "\n",
    "ConfidNet is designed as a small multilayer perceptron composed of a succession of dense layers with a final sigmoid activation that outputs $C(\\pmb{x};\\pmb{\\theta})\\in[0,1]$. We use a mean-square-error (MSE) loss to train this model:\n",
    "\\begin{equation} \n",
    "\\mathcal{L}_{\\text{conf}}(\\pmb{\\theta};\\mathcal{D}) = \\frac{1}{N} \\sum_{n=1}^N \\big(C(\\pmb{x}_n;\\pmb{\\theta}) - \\text{TCP}_F(\\pmb{x}_n,y_n)\\big)^2.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thome.isir.upmc.fr/classes/MVA/confidnet.jpg\" title=\"ConfidNet\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwA9VViv5Zpx"
   },
   "outputs": [],
   "source": [
    "class LeNetConfidNet(nn.Module):\n",
    "    ''' A LeNet-syle model equipped with ConfidNet auxiliary branch '''\n",
    "    def __init__(self, n_classes=10):\n",
    "        super(LeNetConfidNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*32, 100)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "        # ConfidNet Layers\n",
    "        self.uncertainty1 = nn.Linear(100, 400)\n",
    "        self.uncertainty2 = nn.Linear(400, 400)\n",
    "        self.uncertainty3 = nn.Linear(400, 400)\n",
    "        self.uncertainty4 = nn.Linear(400, 400)\n",
    "        self.uncertainty5 = nn.Linear(400, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "       # Max pooling over a (2, 2) window\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, self.num_flat_features(out))\n",
    "        out = F.dropout(out, 0.5, training=self.training)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.dropout(out, 0.25, training=self.training)\n",
    "\n",
    "        # Uncertainty prediction\n",
    "        uncertainty = F.relu(self.uncertainty1(out))\n",
    "        uncertainty = F.relu(self.uncertainty2(uncertainty))\n",
    "        uncertainty = F.relu(self.uncertainty3(uncertainty))\n",
    "        uncertainty = F.relu(self.uncertainty4(uncertainty))\n",
    "        uncertainty = self.uncertainty5(uncertainty)\n",
    "  \n",
    "        pred = self.fc2(out)\n",
    "        return pred, uncertainty\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        \n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-28ioCu8Wsb"
   },
   "outputs": [],
   "source": [
    "class SelfConfidMSELoss(nn.modules.loss._Loss):\n",
    "    ''' MSE Loss for confidence learning '''\n",
    "    def __init__(self, num_classes,device):\n",
    "        self.nb_classes = num_classes\n",
    "        self.device = device\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        probs = F.softmax(input[0], dim=1)\n",
    "        confidence = torch.sigmoid(input[1]).squeeze()\n",
    "        labels_hot = torch.eye(10)[target.flatten()].to(device)\n",
    "        loss = (confidence - (probs * labels_hot).sum(dim=1)) ** 2\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lW0YYGKI8fVs"
   },
   "source": [
    "**We train only the ConfidNet layers for 50 epochs. During confidence learning, original classification layers are fixed to keep predictions unchanged.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7U5DzHk8Zg2"
   },
   "outputs": [],
   "source": [
    "lenet_confidnet = LeNetConfidNet(n_classes=10).to(device)\n",
    "lenet_confidnet.load_state_dict(torch.load('lenet_final.cpkt'), strict=False)\n",
    "lenet_confidnet.train()\n",
    "optimizer = torch.optim.Adam(lenet_confidnet.parameters(), lr=1e-4)\n",
    "criterion = SelfConfidMSELoss(10,device)\n",
    "\n",
    "tbatch =100\n",
    "nb_epochs=50\n",
    "nbbatchs = int(X_train.shape[0]/100)\n",
    "\n",
    "# Freezing every layer except uncertainty for confidence training\n",
    "for param in lenet_confidnet.named_parameters():\n",
    "    if \"uncertainty\" in param[0]:\n",
    "        continue\n",
    "    param[1].requires_grad = False\n",
    "\n",
    "best_aupr = 0.0\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    lenet_confidnet.train()\n",
    "\n",
    "    total_loss, correct = 0.0, 0.0\n",
    "    errors, uncertainty = [], []\n",
    "\n",
    "    for i in range(nbbatchs):\n",
    "        X_batch = X_train[i*100:(i+1)*100,:,:]\n",
    "        y_batch = y_train[i*100:(i+1)*100]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = lenet_confidnet(X_batch)\n",
    "        probs = F.softmax(output[0], dim=1)\n",
    "        pred = probs.max(dim=1)[1]\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        correct += (pred == y_batch).sum()\n",
    "        errors.extend((pred != y_batch.view_as(pred)).detach().to(\"cpu\").numpy())\n",
    "        uncertainty.extend(output[1].squeeze().detach().to(\"cpu\").numpy())\n",
    "\n",
    "    errors_test, uncertainty_test = [], []\n",
    "    lenet_confidnet.eval()\n",
    "    nbbatchstest = int(X_test.shape[0]/tbatch)\n",
    "    for i in range(nbbatchstest):\n",
    "        X_batch = X_test[i*100:(i+1)*100,:,:]\n",
    "        y_batch = y_test[i*100:(i+1)*100]\n",
    "        with torch.no_grad():\n",
    "          output = lenet_confidnet(X_batch)\n",
    "        pred = output[0].max(dim=1)[1]\n",
    "        errors_test.extend((pred != y_batch.view_as(pred)).detach().to(\"cpu\").numpy())\n",
    "        uncertainty_test.extend(output[1].squeeze().detach().to(\"cpu\").numpy())\n",
    "\n",
    "    errors = np.reshape(errors, newshape=(len(errors), -1)).flatten()\n",
    "    uncertainty = np.reshape(uncertainty, newshape=(len(uncertainty), -1)).flatten()\n",
    "    aupr = average_precision_score(errors, -uncertainty)\n",
    "    errors_test = np.reshape(errors_test, newshape=(len(errors_test), -1)).flatten()\n",
    "    uncertainty_test = np.reshape(uncertainty_test, newshape=(len(uncertainty_test), -1)).flatten()\n",
    "    print(f\"[Epoch {e + 1}] loss: {total_loss/ X_train.shape[0]:.2E}\"+\n",
    "          f\"\\t accuracy_train: {correct / X_train.shape[0]:.2%}\"+\n",
    "          f\"\\t aupr_train: {aupr:.2%}\"+\n",
    "          f\"\\t aupr_test: {average_precision_score(errors_test, -uncertainty_test):.2%}\")\n",
    "    if aupr>best_aupr:\n",
    "      best_aupr = aupr\n",
    "      torch.save(lenet_confidnet.state_dict(), 'lenet_confidnet_best.cpkt')\n",
    "\n",
    "lenet_confidnet.load_state_dict(torch.load('lenet_confidnet_best.cpkt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8K1mS9Qr8pc"
   },
   "outputs": [],
   "source": [
    "# If you already train your model, you can load it instead using :\n",
    "#lenet_confidnet.load_state_dict(torch.load('lenet_confidnet_best.cpkt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s_J1yxPr96u"
   },
   "source": [
    "### **II.2 Evaluate failure prediction performances**\n",
    "\n",
    "**We compare the capacity of ConfidNet to detect failures with previous baselines (MCP and MCDropout with variation-ratio).**\n",
    "\n",
    "To measure performances, we use the *Area under the Precision-Recall* curve (AUPR). The precision-recall (PR) curve is the graph of the precision $= \\mathrm{TP}/(\\mathrm{TP} + \\mathrm{FP})$ as a function of the recall $= \\mathrm{TP}/(\\mathrm{TP} + \\mathrm{FN})$ where $\\mathrm{TP}$, $\\mathrm{TN}$, $\\mathrm{FP}$ and $\\mathrm{FN}$ are the numbers of true positives, true negatives, false positives and false negatives respectively. In our experiments, classification errors are used as the positive detection class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFzVEt6qKa7j"
   },
   "source": [
    "**We can use the following function for test set prediction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JwYTc92KVSz"
   },
   "outputs": [],
   "source": [
    "#@title **[CODING TASK]** Implement variational-ratio, entropy and mutual information\n",
    "\n",
    "def predict_test_set(model, X_test,y_test, mode='mcp', s=100, temp=5, epsilon=0.0006, verbose=True):\n",
    "    \"\"\"Predict on a test set given a model \n",
    "    # and a chosen method to compute uncertainty estimate\n",
    "    # (mcp, MC-dropout with var-ratios/entropy/mutual information \n",
    "    # ConfidNet and ODIN)\n",
    "\n",
    "    Args:\n",
    "      model: (nn.Module) a trained model\n",
    "      X_test,y_test: Data & labels\n",
    "      mode: (str) chosen uncertainty estimate method (mcp, var-ratios, entropy, mi, odin)\n",
    "      s: (int) number of samples in MCDropout\n",
    "      temp: (int, optional) value of T for temperature scaling in ODIN\n",
    "      epsilon: (float, optional) value of epsilon for inverse adversarial perturbation in ODIN\n",
    "      verbose: (bool, optional) printing progress bar when predicting   \n",
    "      \n",
    "    Returns:\n",
    "      pred: (tensor) class predictions by the model\n",
    "      labels: (tensor) true labels of the given dataset\n",
    "      uncertainties: (tensor) uncertainty estimates of the given dataset\n",
    "      errors: (tensor) 0/1 vector whether the model wrongly predicted a sample\n",
    "      hists : (array) number of occurences by class in each sample fo the given dataset, only with MCDropout\n",
    "      mc_samples: (tensor) prediction matrix for s=100 samples, only with MCDropout\n",
    "    \"\"\"\n",
    "    tbatch =100\n",
    "    nbbatchs = int(X_test.shape[0]/100)\n",
    "\n",
    "    preds, uncertainties, labels, errors  = [], [], [], []\n",
    "    mc_samples, hists = [], []\n",
    "    model.eval()\n",
    "    \n",
    "    #loop = tqdm(test_loader, disable=not verbose)\n",
    "    for i in range(nbbatchs):\n",
    "        images = X_test[i*100:(i+1)*100,:,:]\n",
    "        targets = y_test[i*100:(i+1)*100]\n",
    "\n",
    "        if mode in ['mcp','odin']:\n",
    "            model.training = False           \n",
    "            if mode=='odin':\n",
    "                # Coding task in Section 3: implement ODIN\n",
    "                images = odin_preprocessing(model,images,epsilon).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(images)\n",
    "            if isinstance(output,tuple):\n",
    "                output = output[0]\n",
    "            if mode =='odin':\n",
    "                output = output / temp\n",
    "            confidence, pred = F.softmax(output, dim=1).max(dim=1, keepdim=True)\n",
    "            confidence = confidence.detach().to('cpu').numpy()\n",
    "            \n",
    "        elif mode in ['var-ratios', 'entropy', 'mut_inf']:\n",
    "            model.training = True\n",
    "            outputs = torch.zeros(images.shape[0], s, 10)\n",
    "            for i in range(s):\n",
    "                with torch.no_grad():\n",
    "                    outputs[:,i] = model(images)\n",
    "            mc_probs = F.softmax(outputs, dim=2)\n",
    "            predicted_class = mc_probs.max(dim=2)[1]\n",
    "            pred = mc_probs.mean(1).max(dim=1, keepdim=True)[1]\n",
    "            mc_samples.extend(mc_probs)\n",
    "            hist = np.array([np.histogram(predicted_class[i,:], range=(0,10))[0]  \n",
    "                              for i in range(predicted_class.shape[0])])\n",
    "            hists.extend(hist)\n",
    "            \n",
    "            # ============ YOUR CODE HERE ============\n",
    "            if mode=='var-ratios':\n",
    "                # You may want to use the hist variable here\n",
    "                confidence = 1. - hist.max(axis=1)/s\n",
    "            elif mode=='entropy':\n",
    "                confidence = -(mc_probs.mean(1)*torch.log(mc_probs.mean(1)+1e-9)).sum(dim=1)\n",
    "            elif mode=='mut_inf':\n",
    "                confidence = -(mc_probs.mean(1)*torch.log(mc_probs.mean(1)+1e-9)).sum(dim=1) \\\n",
    "                                    + (mc_probs*torch.log(mc_probs+1e-9)).sum(dim=2).mean(dim=1)\n",
    "            # ======================================= \n",
    "        \n",
    "        elif mode=='confidnet':\n",
    "          with torch.no_grad():\n",
    "            output, confidence = model(images)\n",
    "          _, pred = F.softmax(output, dim=1).max(dim=1, keepdim=True)\n",
    "          confidence = confidence.detach().to('cpu').numpy()\n",
    "\n",
    "        preds.extend(pred)\n",
    "        labels.extend(targets)\n",
    "        uncertainties.extend(confidence)\n",
    "        errors.extend((pred.to(device)!=targets.view_as(pred)).detach().to(\"cpu\").numpy())\n",
    "\n",
    "    preds = np.reshape(preds, newshape=(len(preds), -1)).flatten()\n",
    "    labels = np.reshape(labels, newshape=(len(labels), -1)).flatten()\n",
    "    uncertainties = np.reshape(uncertainties, newshape=(len(uncertainties), -1)).flatten()\n",
    "    errors = np.reshape(errors, newshape=(len(errors), -1)).flatten()\n",
    "\n",
    "    if mode in ['var-ratios', 'entropy', 'mi']:\n",
    "        hists = np.reshape(hists, newshape=(len(hists), -1))\n",
    "\n",
    "    print(f'Test set accuracy = {(preds == labels).sum()/len(preds):.2%}')\n",
    "    \n",
    "    return preds, labels, uncertainties, errors, hists, mc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQYcfUi1y6Um"
   },
   "outputs": [],
   "source": [
    "#@title **[CODING TASK]** Compute precision and recall vectors along with AUPR score for ConfidNet\n",
    "\n",
    "# ============ YOUR CODE HERE ============\n",
    "# Use predict_test_set function to obtain confidence estimates\n",
    "# with previous model, choosing 'confidnet' mode. \n",
    "# Then then calculate the precision, recall and aupr \n",
    "# with sklearn functions.\n",
    "# /!\\ In failure prediction, errors are consider \n",
    "# as the positive class\n",
    "\n",
    "\n",
    "aupr_confidnet = None\n",
    "precision_confidnet, recall_confidnet = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLkWRtSeLnmx"
   },
   "outputs": [],
   "source": [
    "#@title **[CODING TASK]** Same with MCP\n",
    "\n",
    "# ============ YOUR CODE HERE ============\n",
    "# Mode = 'mcp'\n",
    "aupr_mcp = None\n",
    "precision_mcp, recall_mcp = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCgYBt84MPNR"
   },
   "outputs": [],
   "source": [
    "#@title **[CODING TASK]** Same with MCDropout \n",
    "\n",
    "# ============ YOUR CODE HERE ============\n",
    "# Mode = 'entropy'\n",
    "aupr_mc_dropout = None\n",
    "precision_mc_dropout, recall_mc_dropout = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iZZGHN3MgQS"
   },
   "source": [
    "**Let**'s look at the comparative results for failure prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ul5KNripMiA8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(recall_mcp, precision_mcp, label = f'MCP, AUPR = {aupr_mcp:.2%}')\n",
    "plt.plot(recall_mc_dropout, precision_mc_dropout, label = f'MCDropout (var-ratio), AUPR = {aupr_mc_dropout:.2%}')\n",
    "plt.plot(recall_confidnet, precision_confidnet, label = f'ConfidNet, AUPR = {aupr_confidnet:.2%}')\n",
    "plt.title('Precision-recall curves for failure prediction')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Out-of-distribution detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern neural networks are known to generalize well when the training and testing data are sampled from the same distribution. However, when deploying neural networks in real-world applications, there is often very little control over the testing data distribution. It is important for classifiers to be aware of uncertainty when shown new kinds of inputs, i.e., out-of- distribution examples. Therefore, being able to accurately detect out-of-distribution examples can be practically important for visual recognition tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thome.isir.upmc.fr/classes/MVA/ood.png\" title=\"OOD detection\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use Kuzushiji-MNIST, a drop-in replacement for the MNIST dataset (28x28 grayscale, 70,000 images) containing 3832 Kanji (japanese) characters, as out-of-distribution sample to our model trained on MNIST. We will compare the methods for uncertainty estimates used previously and ODIN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load KMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "kmnist_test_dataset = datasets.KMNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "!wget https://thome.isir.upmc.fr/classes/MVA/Kmnist-data-test.pcl\n",
    "outfile = 'Kmnist-data-test.pcl'\n",
    "[X_testK, y_testK] = pickle.load( open( outfile, \"rb\" ) )\n",
    "\n",
    "X_testK = X_testK.to(device)\n",
    "y_testK = y_testK.to(device)\n",
    "\n",
    "# Visualize some images\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4)\n",
    "for i in range(16):\n",
    "    if i >= 16:\n",
    "        break\n",
    "    axes[i // 4][i % 4].imshow(X_testK.cpu()[i][0], cmap='gray')\n",
    "    axes[i // 4][i % 4].set_title(f\"{kmnist_test_dataset.classes[y_testK[i]]}\")\n",
    "    axes[i // 4][i % 4].set_xticks([])\n",
    "    axes[i // 4][i % 4].set_yticks([])\n",
    "fig.set_size_inches(4, 4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We compute the precision, recall and AUPR metric for OOD detection with MCP and MCDropout with var-ratios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions for MCP method on MNIST\n",
    "_, _, uncertainty_mcp, errors_mcp, _, _ = predict_test_set(net, X_test,y_test, mode='mcp')\n",
    "\n",
    "# Same on KMNIST\n",
    "_, _, uncertainty_kmnist, errors_kmnist, _, _ = predict_test_set(net, X_testK,y_testK, mode='mcp')\n",
    "\n",
    "# Concatenating predictions with MNIST, considering KMNIST samples as out-of-distributions\n",
    "tot_uncertainty = np.concatenate((uncertainty_mcp, uncertainty_kmnist))\n",
    "in_distribution = np.concatenate((np.zeros_like(uncertainty_mcp), np.ones_like(uncertainty_kmnist)))\n",
    "\n",
    "# Obtaining precision and recall plot vector + AUPR\n",
    "precision_ood_mcp, recall_ood_mcp, _ = precision_recall_curve(in_distribution, -tot_uncertainty)\n",
    "aupr_ood_mcp = average_precision_score(in_distribution, -tot_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing for MCDropout with var-ratios\n",
    "_, _, uncertainty_mc_dropout, _, _, _ = predict_test_set(net, X_test,y_test, mode='var-ratios')\n",
    "_, _, uncertainty_mc_dropout_kmnist, _, _, _ = predict_test_set(net, X_testK,y_testK, mode='var-ratios')\n",
    "tot_uncertainty = np.concatenate((uncertainty_mc_dropout, uncertainty_mc_dropout_kmnist))\n",
    "in_distribution = np.concatenate((np.zeros_like(uncertainty_mc_dropout), np.ones_like(uncertainty_mc_dropout)))\n",
    "\n",
    "precision_ood_mc_dropout, recall_ood_mc_dropout, _ = precision_recall_curve(in_distribution, tot_uncertainty)\n",
    "aupr_ood_mc_dropout = average_precision_score(in_distribution, tot_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement the ODIN method.\n",
    "\n",
    "ODIN [[Liang et al., ICLR 2018](https://openreview.net/pdf?id=H1VGkIxRZ)], is a threshold-based detector enhancing maximum softmax probabilities with two extensions:\n",
    "- **temperature scaling**: \n",
    "\t$ \\textit{p}(y= c \\vert \\mathbf{x}, \\mathbf{w}, T) = \\frac{\\exp(f_c( \\mathbf{x}, \\mathbf{w}) / T)}{\\sum_{k=1}^K \\exp(f_k( \\mathbf{x}, \\mathbf{w}) / T)} $\n",
    "where $T \\in \\mathbb{R}^{+}$\n",
    "- **inverse adversarial perturbation**: $ \\tilde{\\mathbf{x}} = \\mathbf{x} - \\epsilon \\mathrm{sign} \\big ( - \\nabla_x \\log (\\textit{p}(y = \\hat{y} \\vert \\mathbf{x}, \\mathbf{w}, T) \\big ) $\n",
    "\n",
    "Both technics aimed to increase in-distribution MCP higher than out-distribution MCP. Here, we set the hyperparameters $T=5$ and $\\epsilon=0.0014$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **[CODING TASK]** Implement ODIN preprocessing\n",
    "\n",
    "def odin_preprocessing(model, input, epsilon):      \n",
    "    # We perform the invese adversarial perturbation\n",
    "    # You can find some help in the link below:\n",
    "    # https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "\n",
    "    # ============ YOUR CODE HERE ============\n",
    "    # 1. Set requires_grad attribute of tensor. Important for Attack\n",
    "\n",
    "    # 2. Forward pass the data through the model\n",
    "\n",
    "    # 3. Calculate the loss w.r.t to class predictions\n",
    "\n",
    "    # 4. Zero all existing gradients\n",
    "\n",
    "    # 5. Calculate gradients of model in backward pass\n",
    "\n",
    "    # 6. Collect sign of datagrad\n",
    "\n",
    "    # 7. Normalizing the gradient to the same space of image\n",
    "    sign_input_grad = sign_input_grad / 0.3081\n",
    "\n",
    "    # 8. Apply FGSM Attack\n",
    "\n",
    "    return perturbed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions for ODIN on MNIST\n",
    "_, _, uncertainty_odin, errors_odin, _, _ = predict_test_set(net, X_test,y_test, mode='odin', temp=5, epsilon=0.0014)\n",
    "\n",
    "# Compute predictions for ODIN on KMNIST\n",
    "_, _, uncertainty_kmnist, errors_kmnist, _, _ = predict_test_set(net, X_testK,y_testK, mode='odin', temp=5, epsilon=0.0014)\n",
    "\n",
    "# Concatenating predictions with MNIST, considering KMNIST samples as out-of-distributions\n",
    "tot_uncertainty = np.concatenate((uncertainty_odin, uncertainty_kmnist))\n",
    "in_distribution = np.concatenate((np.zeros_like(uncertainty_odin), np.ones_like(uncertainty_kmnist)))\n",
    "\n",
    "# Obtaining precision and recall plot vector + AUPR\n",
    "precision_ood_odin, recall_ood_odin, _ = precision_recall_curve(in_distribution, -tot_uncertainty)\n",
    "aupr_ood_odin = average_precision_score(in_distribution, -tot_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Precision-recall curve for OOD detection')\n",
    "plt.plot(recall_ood_mcp, precision_ood_mcp, label = f'MCP, AUPR = {aupr_ood_mcp:.2%}')\n",
    "plt.plot(recall_ood_mc_dropout, precision_ood_mc_dropout, label = f'MCDropout (var-ratios), AUPR = {aupr_ood_mc_dropout:.2%}')\n",
    "plt.plot(recall_ood_odin, precision_ood_odin, label = f'ODIN, AUPR = {aupr_ood_odin:.2%}')\n",
    "plt.legend()\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question 3.1]: Compare the precision-recall curves of each OOD method along with their AUPR values. Which method perform best and why?**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP3_uncertainty_applications.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
